<!DOCTYPE html>
<html lang="en">

  <head>
  

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Site description">
  <meta name="author" content="Lin">
  <link rel="canonical" href="http://localhost:4000/">

  <title>VoxBlink2: A 100K+ Speaker Recognition Corpus and Open-Set Speaker-Identification Benchmark</title>

  <!-- Bootstrap core CSS -->
  <link href="assets/css/bootstrap.min.css" rel="stylesheet" />

  <!-- Custom fonts for this template -->
  <link href="assets/css/all.min.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
  <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>
  <script src="assets/js/marked.min.js"></script>
  <script src="assets/js/echarts.min.js"></script>

  <!-- Custom styles for this theme -->
  <!--<link href="assets/css/agency.min.css" rel="stylesheet">-->
  <link href="assets/css/agency.css" rel="stylesheet" />

  <!-- Page container change top padding when nav shrinks -->
  
</head>


  <body id="page-top">

        <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
    <div class="container">
	  <a class="navbar-brand js-scroll-trigger" href="#page-top">VoxBlink2</a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav text-uppercase ml-auto">
        
        
          <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#services">About</a></li>
        
          <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#portfolio">Features</a></li>
        
          <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">Publications</a></li>
        
          <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#timeline">Download</a></li>
                
          <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#acknowledgement">Acknowledgement</a></li> -->
                
        
        </ul>
      </div>
    </div>
  </nav>
  <!-- End Navigation -->
  
  <!-- Header -->
  
  <header class="faces-mask masthead" style="background-image: 100% 80%;max-height: 800px;">
    <div class="container"  style="max-width: 95%;">
      <div class="intro-text">
        <div class="intro-lead-in">
        <img src="assets/img/wordcloud_color.png" width="750" height="170">
        </div>
        <div class="intro-heading text-uppercase" style="font-size: 25pt;">
          <p>A 100K+ Speaker Recognition Corpus and <br>Open-Set Speaker-Identification Benchmark</p>
        </div>
        <a class="btn btn-primary btn-xl text-uppercase js-scroll-trigger" href="#services" style="color: black;margin-right: 10px;">Let's Start!</a>
        <a class="btn btn-primary btn-xl text-uppercase js-scroll-trigger" href="https://voxblink.github.io" style="color: black;margin-left: 10px;">See VoxBlink1</a>        
      </div>
    </div>
  </header>
  
  <!-- End Header -->
<span class="text-muted" style="float: right;margin-right: 15pt;margin-top:5pt;font-size:large;">The wordcloud is generated by the videos' tags.</span>
<!-- Services -->

  <section class="page-section" id="services">

    <div class="container" >
      <div class="row">
        <div class="col-lg-12 text-center">
          <h2 class="section-heading text-uppercase">About</h2>
          
          <h3 class="section-subheading text-muted">
            Important Notice: The released dataset only contains annotation data, 
            including the YouTube links, time stamps and speaker labels. 
            We do not release audio or visual data and 
            it is the user's responsibility to decide whether and 
            how to download the video data and whether their intended purpose with the downloaded data is legal in their country.
          </h3>
		  
        </div>
      </div>
	  
      <div class="row text-center">
	  
        <div class="col-md-4">
          <span class="fa-stack fa-4x">
            <i class="fas fa-circle fa-stack-2x text-primary"></i>
            <i class="fas fa-file-audio fa-stack-1x fa-inverse"></i>
          </span>
          <h4 class="service-heading"><p>10M Utterances</p>
</h4>
          <div class="text-muted">
            <p>
              We annotate approximate 10M audio/video segments from videos on YouTube, 
              encompassing various contexts including podcasts, lives, live streaming highlights, etc.
            </p>
</div>
        </div>
	  
        <div class="col-md-4">
          <span class="fa-stack fa-4x">
            <i class="fas fa-circle fa-stack-2x text-primary"></i>
            <i class="fas fa-user fa-stack-1x fa-inverse"></i>
          </span>
          <h4 class="service-heading">
            <p>110K+ speakers</p>
          </h4>
          <div class="text-muted">
            <p>Our dataset spans over 15 different language families, boasting multilingual characteristics. </p>
        </div>
        </div>
	  
        <div class="col-md-4">
          <span class="fa-stack fa-4x">
            <i class="fas fa-circle fa-stack-2x text-primary"></i>
            <i class="fas fa-clock fa-stack-1x fa-inverse"></i>
          </span>
          <h4 class="service-heading"><p>1.6w Hours</p>
</h4>
          <div class="text-muted">
            <p>The scenarios covered align with real-life situations, and the audio/videos from a single speaker vary over time.</p>
        </div>
        </div>
	  
      </div>
	  
    </div>
  </section>

<!-- End Services -->
<!-- Portfolio Grid -->

<section class="bg-light page-section" id="portfolio">
  <div class="container">
    <div class="row">
      <div class="col-lg-12 text-center">
        <h2 class="section-heading text-uppercase">
          <p>Language Distribution</p>
        </h2>
        <h3 class="section-subheading text-muted">
          <p>
            Explore the lingual characteristics of the VoxBlink2! 
            It's noted that the language labels are derived from the language detection tool of the video tags, 
            so they are not very accurate, just for reference. 
          </p>
        </h3>
      </div>
    </div>
    <table class="table table-striped" style="max-width: 100%;">
      <thead>
        <tr>
          <th scope="col">#</th>
          <th scope="col">Language</th>
          <th scope="col">Speakers</th>
          <th scope="col">#</th>
          <th scope="col">Language</th>
          <th scope="col">Speakers</th>
          <th scope="col">#</th>
          <th scope="col">Language</th>
          <th scope="col">Speakers</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th scope="row">1</th>
          <td>English</td>
          <td>40000+</td>
          <th scope="row">7</th>
          <td>Vietnam</td>
          <td>1793</td>
          <th scope="row">13</th>
          <td>Japanese</td>
          <td>992</td>
        </tr>
        <tr>
          <th scope="row">2</th>
          <td>Portuguese</td>
          <td>6227</td>
          <th scope="row">8</th>
          <td>Korean</td>
          <td>1544</td>
          <th scope="row">14</th>
          <td>Estonian</td>
          <td>725</td>
        </tr>
        <tr>
          <th scope="row">3</th>
          <td>Spanish</td>
          <td>6009</td>
          <th scope="row">9</th>
          <td>Italian</td>
          <td>1519</td>
          <th scope="row">15</th>
          <td>Norwegian</td>
          <td>574</td>
        </tr>
        <tr>
          <th scope="row">4</th>
          <td>Russian</td>
          <td>3961</td>
          <th scope="row">10</th>
          <td>French</td>
          <td>1503</td>
          <th scope="row">16</th>
          <td>Polish</td>
          <td>490</td>
        </tr>
        <tr>
          <th scope="row">5</th>
          <td>Arabic</td>
          <td>3467</td>
          <th scope="row">11</th>
          <td>German</td>
          <td>1150</td>
          <th scope="row">17</th>
          <td>Tagalog</td>
          <td>467</td>
        </tr>
        <tr>
          <th scope="row">6</th>
          <td>Indonesian</td>
          <td>1864</td>
          <th scope="row">12</th>
          <td>Turkish</td>
          <td>1150</td>
          <th scope="row">18</th>
          <td>Catalan</td>
          <td>407</td>
        </tr>
      </tbody>
    </table>
    
	
    </div>
  </div>

</section>

<section class="page-section" id="style" style="height:700px; padding-bottom: 10px;padding-top: 20px;">
  <div class="container" >
    <div class="row">
      <div class="col-lg-12 text-center" style="height: 100px;">
        <h2 class="section-heading text-uppercase">
          <p>Theme</p>
        </h2>
        <h3 class="section-subheading text-muted">
          <p>
            Explore the Themes of the VoxBlink2!
          </p>
        </h3>
      </div>
      <div id="theme-container" style="height: 500px;width: 100%;">
        <script type="text/javascript">
            // 基于准备好的dom，初始化echarts实例
            var myChart = echarts.init(document.getElementById('theme-container'));
            // 指定图表的配置项和数据
            var option = {
                title: {
                  
                },
                tooltip: {},
                legend: {
                    data:['销量']
                },
                xAxis: {
                    data: ["People&Blogs","Entertainment","Education","Music","Style","Sports",
                      'Science','Travel','News','Film',"Gaming","Comedy",'Vehicles','Nonprofits','Pets'
                    ],
                    axisLabel: {
                    interval:0,
                    rotate:40
                },  
                },
                yAxis: [
                    {                   
                        type: 'value',
                        axisLabel: {formatter: '{value} K'},
                    }
                ],
                series: [{
                    name: 'Nums of Videos(w)',
                    type: 'bar',
                    data: [1292, 471, 431, 343, 
                    264, 72,70,69,66,
                    66,64,61,24,23,11],
                    itemStyle: {
                    normal: {
                      label: {
                        show: true, //开启显示
                        position: 'top', //在上方显示
                        textStyle: { //数值样式
                          color: 'black',
                          fontSize: 16
                        }
                      }
                    }
                  },
                }]
            };
     
            // 使用刚指定的配置项和数据显示图表。
            myChart.setOption(option);
          </script>
      </div>
    </div>
    
    </div>
  </div>

</section>
<!-- Portfolio Modals -->



<!-- About -->

<section class="bg-light page-section" id="about">
  <div class="container"  >
    <div class="row">
      <div class="col-lg-12 text-center">
        <h2 class="section-heading text-uppercase">Publications</h2>
        <h3 class="section-subheading text-muted">Please cite the following if you make use of the dataset.</h3>
        <h5 class="section-heading text-muted" style=" font-family: 'Times New Roman', Times, serif;">Yuke Lin
          , Ming Cheng, Fulin Zhang, Yingying Gao, Shilei Zhang, Ming Li</h5>
        <h4 class="section-heading" style="font-family: 'Times New Roman', Times, serif;">VoxBlink2: A 100K+ Speaker Recognition Corpus and the Open-Set Speaker-Identification Benchmark, INTERSPEECH2024</h4>
      </div>
    </div>
    <div class="row" style="margin-top: 0pt;">
      <div class="col-lg-8 mx-auto text-center">
        <div class="large text-muted">
          <h5>
            <a href="" class="portfolio-link" data-toggle="modal">Bibtex</a>&nbsp;|&nbsp;
            <a href="#p8" class="portfolio-link" data-toggle="modal">Abstract</a>&nbsp;|&nbsp;
            <a href="https://arxiv.org/abs/2407.11510">PDF</a>&nbsp;&nbsp;
          </h5>
        </div>
      </div>
    </div>
  </div>
</section>

<div
  class="portfolio-modal modal fade"
  id="p7"
  tabindex="-1"
  role="dialog"
  aria-hidden="true"
>
  <div class="modal-dialog" style="margin: 10rem;">
    <div class="modal-content">
      <div class="close-modal" data-dismiss="modal">
        <div class="lr">
          <div class="rl"></div>
        </div>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h2 class="text-primary">Bibtex</h2>
            <div class="modal-body">
              <!-- <h2 class="text-uppercase">Duration</h2> -->
              
              <!-- Project Details Go Here -->
              <textarea name="message" class="form-control" id="message" rows="10">
                @INPROCEEDINGS{10446780,
                  author={Lin, Yuke and Qin, Xiaoyi and Zhao, Guoqing and Cheng, Ming and Jiang, Ning and Wu, Haiying and Li, Ming},
                  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
                  title={Voxblink: A Large Scale Speaker Verification Dataset on Camera}, 
                  year={2024},
                  volume={},
                  number={},
                  pages={10271-10275},
                  keywords={Training;Video on demand;Purification;Pipelines;Signal processing;Web sites;Noise measurement;Speaker Verification;Dataset;Large-scale;Multi-modal},
                  doi={10.1109/ICASSP48485.2024.10446780
                  }}
              </textarea>
              <p>
                <!-- <p class="item-intro"></p> -->
              </p>
  
            </div>
            <button
            class="btn btn-primary"
            data-dismiss="modal"
            type="button"
          >
            <i class="fas fa-times"></i>
            Close
          </button>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div
  class="portfolio-modal modal fade"
  id="p8"
  tabindex="-1"
  role="dialog"
  aria-hidden="true"
>
  <div class="modal-dialog" style="margin: 10rem;">
    <div class="modal-content">
      <div class="close-modal" data-dismiss="modal">
        <div class="lr">
          <div class="rl"></div>
        </div>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h2 class="text-uppercase">Abstract</h2>
            <div class="modal-body" style="text-align: left;">
              <!-- <h2 class="text-primary">Bibtex</h2> -->
              <!-- Project Details Go Here -->
              
              <span >
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In this paper, we provide a large audio-visual speaker recognition dataset, <strong>VoxBlink2</strong>, which includes approximately 10M utterances with videos from 110K+ speakers in the wild. This dataset represents a significant expansion over the VoxBlink dataset, encompassing a broader diversity of speakers and scenarios by the grace of an optimized data collection pipeline. Afterward, we explore the impact of training strategies, data scale, and model complexity on speaker verification and finally establish a new single-model state-of-the-art EER at 0.170% and minDCF at 0.006% on the VoxCeleb1-O test set. Such remarkable results motivate us to explore speaker recognition from a new challenging perspective. We raise the Open-Set Speaker-Identification task, which is designed to either match a probe utterance with a known gallery speaker or categorize it as an unknown query. Associated with this task, we design concrete benchmark and evaluation protocols. 
              </span>
              <p>
                <!-- <p class="item-intro"></p> -->
              </p>

            </div>
            <button
            class="btn btn-primary"
            data-dismiss="modal"
            type="button"
          >
            <i class="fas fa-times"></i>
            Close
          </button>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End About -->
<!-- About -->

  <section class="page-section" id="timeline">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
          <h2 class="section-heading text-uppercase"><p>Guidance</p>
</h2>
          <h3 class="section-subheading text-muted">Build your VoxBlink2</h3>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-12">
          <h4 >Resource</h4>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-12" style="font-size: large;">
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          Following a similar pipeline like the VoxBlink's, the annotation files can be downloaded through <a href="https://drive.google.com/drive/folders/1lzumPsnl5yEaMP9g2bFbSKINLZ-QRJVP?usp=drive_link"><strong>here</strong></a>. 
          Apart from annotation files, we also provide the following files:
         
          <br>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          1. The meta-informations of videos are saved in <code>./spk_info</code>, which include <strong>upload-time, themes and video tags</strong>,etc.
          <br>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          2. In order to better handle multimodal processing, we provide <strong>transcription annotations</strong> implemented by <a href="https://github.com/openai/whisper">Whisper-medium</a>. 
          We will release the ASR predicted transcript with Whisper Large model in the near future.
          <br>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          3. Different size of speaker <a href="https://drive.google.com/drive/folders/19uUmlnSjmFhffO7vHXO7upZJI77OOmrP">models</a> can be downloaded for evaluation , pre-training or leveraging for speaker-related tasks.
          The largest model performs <strong>0.228%</strong> EER on the Vox1-O evaluation set without any post-processing. 
          When incorporating Score-Norm and QMF, <strong>0.17%</strong> EER and <strong>0.006%</strong> minDCF(ptar=0.01) have been achieved.
          <br>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          If you find it hard to collect all data, you can make a request on the data resource via <a href="https://docs.google.com/forms/d/e/1FAIpQLSdpQ67o3VjC_B6BGCicnf5gjLnQ2YxLgxIZCyyfYVoj8cniUQ/viewform">Link</a> and 
          we'll decide whether to make an assistance based on your information and purpose.
        </div>
      </div>
      <br>
      <div class="row">
        <div class="col-lg-12">
          <h4 >Execute</h4>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-12" style="font-size: large;">
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          After you download the annotation files, you can follow the guidance in 
          <a href="https://github.com/VoxBlink2/ScriptsForVoxBlink2.git"><strong>Repo</strong></a>
          and build your database with <code>vb2_meta.tar.gz</code>. 
          Based on your condition, you can follow the audio-visual or audio-only download recipe to build the corpus.
        </div>
      </div>
      <br>
      <div class="row">
        <div class="col-lg-12">
          <h4 >License</h4>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-12" style="font-size: large;">
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          The open-source resources and the execution scripts are 
          licensed under the <strong>CC BY-NC-SA 4.0</strong> for protection.
          Detailed terms can be found on <a href="https://github.com/VoxBlink2/ScriptsForVoxBlink2/blob/main/LICENSE">LICENSE</a>. 
          The license of the model is also CC BY-NC-SA 4.0, no commercial application is allowed, because the model is trained from voxblink2 and voxceleb, in which the data are coming from youtube.
          If you have some legal concerns of the privacy confliction to use the data, 
          please consult the lawyer in your local region. 
          
          The metadata provided is accurate as of Feb 2024. We cannot guarantee the availability of videos on the YouTube platform in the future. 
          For YouTube users with concerns regarding their videos' inclusion in our dataset, please contact us via E-mail:<strong> yuke.lin@dukekunshan.edu.cn </strong>or <strong>ming.li369@dukekunshan.edu.cn</strong>.

          </div>
      </div>
      <br>
      <div class="row">
        <div class="col-lg-12">
          <h4 >Open-Set Speaker-Identification</h4>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-12" style="font-size: large;">
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          please refer to <a href="https://github.com/VoxBlink2/ScriptsForVoxBlink2">Repo</a> and follow the guidance for evaluation. 
          Make sure that you have colllected the <a href="https://voxblink.github.io">VoxBlink-clean</a> to obtain 
          the fair results.
        </div>
      </div>
    </div>
  </section>
  <div
  class="portfolio-modal modal fade"
  id="p9"
  tabindex="-1"
  role="dialog"
  aria-hidden="true"
>
  <div class="modal-dialog" style="margin: 10rem;">
    <div class="modal-content">
      <div class="close-modal" data-dismiss="modal">
        <div class="lr">
          <div class="rl"></div>
        </div>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h2 class="text-uppercase">Example</h2>
            <div class="modal-body" style="text-align: left;">
                <!-- <h2 class="text-primary">The </h2> -->
                <!-- Project Details Go Here -->
                The documents are speaker-wised saved in <code>'./video_tags'</code> and the line is splited by <code>'\t'</code>.
                <br>
                
                <pre style="background-color: rgb(243,245,250);">
                  <code>
  <span style="color: red;">video_id	user_name	upload_date	Theme	                Tags</span>
  u66ruMnQQhU	Kesha Barrett	20111009	['Entertainment']	['JoJo', 'ATA', 'Power', 'Kick']
  gP1iNTd4uwk	Kesha Barrett	20110516	['Entertainment']	['Jo', 'Barrett', 'Michael', 'Jackson', 'year', 'olds', 'dancing', 'Preschool']
  9j6L7O8ztFM	Kesha Barrett	20110221	['Entertainment']	['Jo-Jo', 'Joseph', 'Breaking', 'boards', 'kids', 'in', 'karate', 'Lancaster', 'SC']
                  </code>
              </pre>
            </div>
            <button
            class="btn btn-primary"
            data-dismiss="modal"
            type="button"
          >
            <i class="fas fa-times"></i>
            Close
          </button>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
<div
  class="portfolio-modal modal fade"
  id="p10"
  tabindex="-1"
  role="dialog"
  aria-hidden="true"
>
  <div class="modal-dialog" style="margin: 10rem;">
    <div class="modal-content">
      <div class="close-modal" data-dismiss="modal">
        <div class="lr">
          <div class="rl"></div>
        </div>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h2 class="text-uppercase">Example</h2>
            <div class="modal-body" style="text-align: left;">
                <!-- <h2 class="text-primary">The </h2> -->
                <!-- Project Details Go Here -->
                The documents are utterance-wised saved in <code>'./time_stamp'</code> and the line is splited by <code>'\t'</code>.
                <br>
                
                <pre style="background-color: rgb(243,245,250);">
                  <code>
                    Identity:       id000066
                    Reference:      P2RrcZY9xOg
                    Start and Duration:     24.590  2.780
                    KBPS:   235.685
                    
                    FRAME   X       Y       W       H
                    
                    000614  576     219     169     221
                    000615  576     217     171     222
                    000616  577     219     170     220
                    000617  577     218     169     220
                    000618  578     218     168     219
                    000619  577     217     173     214
                    000620  577     218     171     219
                    000621  577     221     170     217
                    000622  577     221     170     218
                    ...     ...     ...     ...     ...   
</code>
              </pre>
            </div>
            <button
            class="btn btn-primary"
            data-dismiss="modal"
            type="button"
          >
            <i class="fas fa-times"></i>
            Close
          </button>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End About -->

<!-- Team -->
<!-- 
<section class="page-section" id="team">
<div class="container">
  <div class="row">
	<div class="col-lg-12 text-center">
	  <h2 class="section-heading text-uppercase">OUR AMAZING TEAM</h2>
	  <h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3>
	</div>
  </div>
  <div class="row d-flex justify-content-center">
  
	<div class="col-sm-4">
	  <div class="team-member">
		<img class="mx-auto rounded-circle" src="assets/img/team/500x500.jpg" alt="">
		<h4>Kay Garland</h4>
		<p class="text-muted">Lead Designer</p>
		<ul class="list-inline social-buttons">
		
		  <li class="list-inline-item">
			<a href="https://twitter.com">
			  <i class="fab fa-twitter"></i>
			</a>
		  </li>
		
		  <li class="list-inline-item">
			<a href="https://facebook.com">
			  <i class="fab fa-facebook-f"></i>
			</a>
		  </li>
		
		  <li class="list-inline-item">
			<a href="https://linkedin.com">
			  <i class="fab fa-linkedin-in"></i>
			</a>
		  </li>
		
		</ul>
	  </div>
	</div>
  
	<div class="col-sm-4">
	  <div class="team-member">
		<img class="mx-auto rounded-circle" src="assets/img/team/2.jpg" alt="">
		<h4>Larry Parker</h4>
		<p class="text-muted">Lead Marketer</p>
		<ul class="list-inline social-buttons">
		
		  <li class="list-inline-item">
			<a href="https://twitter.com">
			  <i class="fab fa-twitter"></i>
			</a>
		  </li>
		
		  <li class="list-inline-item">
			<a href="https://facebook.com">
			  <i class="fab fa-facebook-f"></i>
			</a>
		  </li>
		
		  <li class="list-inline-item">
			<a href="https://linkedin.com">
			  <i class="fab fa-linkedin-in"></i>
			</a>
		  </li>
		
		</ul>
	  </div>
	</div>
  
	<div class="col-sm-4">
	  <div class="team-member">
		<img class="mx-auto rounded-circle" src="assets/img/team/500x500.jpg" alt="">
		<h4>Diana Perterson</h4>
		<p class="text-muted">Lead Developer</p>
		<ul class="list-inline social-buttons">
		
		  <li class="list-inline-item">
			<a href="https://twitter.com">
			  <i class="fab fa-twitter"></i>
			</a>
		  </li>
		
		  <li class="list-inline-item">
			<a href="https://facebook.com">
			  <i class="fab fa-facebook-f"></i>
			</a>
		  </li>
		
		  <li class="list-inline-item">
			<a href="https://linkedin.com">
			  <i class="fab fa-linkedin-in"></i>
			</a>
		  </li>
		
		</ul>
	  </div>
	</div>
  
  </div>
  <div class="row">
	<div class="col-lg-8 mx-auto text-center">
	  <div class="large text-muted"><p>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Aut eaque, laboriosam veritatis, quos non quis ad perspiciatis, totam corporis ea, alias ut unde. <strong>Markdown</strong> supported.</p>
</div>
	</div>
  </div>
</div>
</section> -->

<!-- End Team -->

<!-- Clients -->

<!-- Contact -->
<!-- 
<section class="page-section bg-light" id = 'acknowledgement'>
  <div class="container ">
    <div class="row">
      <div class="col-lg-12 text-center">
        <h2 class="section-heading text-uppercase">
          <p>Acknowledgement</p>
</h2>
      </div>
    </div>
    <div class="row">
      <div class="col-lg-12">
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

        This research is funded by China Mobile Research Institute-Wuhan University Systematic Artificial Intelligence Collaboration Platform 
        under the project "Joint Research and Development of Large Voiceprint Model for Telephone Scenarios". Many thanks for the computational resource provided by the Advanced Computing East China Sub-Center.
      </div>
    </div>
  </div>
</section> -->

<!-- End Contact -->


	  <!-- Footer -->
<footer class="footer" id="footer" style="background-color: white">
  <div class="container">
<!--     -->
    <div class="row align-items-center">
      <div class="col-md-4">
        <!-- <span class="copyright"
          >Copyright &copy; DKU</span
        > -->
      </div>
      
      <!-- Legal -->
      
    </div>
    
  </div>
</footer>

<!-- End Footer -->


	  <!-- Bootstrap core JavaScript -->
	  <script src="assets/js/jquery.min.js"></script>
	  <script src="assets/js/bootstrap.bundle.min.js"></script>

	  <!-- Plugin JavaScript -->
	  <script src="assets/js/jquery.easing.min.js"></script>

	  <!-- Contact form JavaScript -->
	  <script src="assets/js/jqBootstrapValidation.js"></script>
	  <script src="assets/js/contact_me.js"></script>

	  <!-- Custom scripts for this template -->
	  <script src="assets/js/agency.min.js"></script>

  </body>
</html>